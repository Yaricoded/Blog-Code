{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35061730-7d66-4e60-a649-f08031f84fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   years  housing  ai_capital  predicted_ai  bubble_signal\n",
      "0      1      100          50     39.369147       1.270030\n",
      "1      2      110          60     56.392992       1.063962\n",
      "2      3      120          70     80.778219       0.866570\n",
      "3      4      140         100    115.708006       0.864244\n",
      "4      5      160         150    165.741989       0.905021\n",
      "5      6      200         220    237.411461       0.926661\n",
      "6      7      250         330    340.071953       0.970383\n",
      "7      8      310         500    487.124475       1.026432\n",
      "8      9      380         750    697.764846       1.074861\n",
      "9     10      450        1100    999.489464       1.100562\n"
     ]
    }
   ],
   "source": [
    "#Python Code: Simple Bubble Detection (AI vs Housing)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Example: Detecting bubble-like growth\n",
    "years = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "housing_index = np.array([100,110,120,140,160,200,250,310,380,450])\n",
    "ai_investment = np.array([50,60,70,100,150,220,330,500,750,1100])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"years\": years,\n",
    "    \"housing\": housing_index,\n",
    "    \"ai_capital\": ai_investment\n",
    "})\n",
    "\n",
    "# Fit linear model to detect if growth is exponential\n",
    "model = LinearRegression()\n",
    "model.fit(df[[\"years\"]], np.log(df[\"ai_capital\"]))\n",
    "\n",
    "predicted = np.exp(model.predict(df[[\"years\"]]))\n",
    "\n",
    "df[\"predicted_ai\"] = predicted\n",
    "df[\"bubble_signal\"] = df[\"ai_capital\"] / df[\"predicted_ai\"]\n",
    "\n",
    "print(df)\n",
    "\n",
    "# If bubble_signal >> 1, potential bubble behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1741471a-f6f3-47c5-b5f1-2eef2db9a19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 0.3955555555555556\n",
      "Teammate Risk Level: High Risk - Reallocate immediately\n"
     ]
    }
   ],
   "source": [
    "#Python Code: Simple ‚ÄúTeam Behavior Risk Model‚Äù\n",
    "import pandas as pd\n",
    "\n",
    "# Example teammate behavior log\n",
    "behavior = pd.DataFrame({\n",
    "    \"task\": [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"],\n",
    "    \"on_time\": [0,1,0,0,1,0],     # 1=on time, 0=late\n",
    "    \"quality\": [2,4,1,1,3,2],    # subjective scoring\n",
    "    \"communication\": [1,3,1,0,2,1] # quality of communication\n",
    "})\n",
    "\n",
    "# Weighted score\n",
    "weights = {\n",
    "    \"on_time\": 0.4,\n",
    "    \"quality\": 0.4,\n",
    "    \"communication\": 0.2\n",
    "}\n",
    "\n",
    "behavior[\"score\"] = (\n",
    "    behavior[\"on_time\"]*weights[\"on_time\"] +\n",
    "    behavior[\"quality\"]*weights[\"quality\"]/5 +\n",
    "    behavior[\"communication\"]*weights[\"communication\"]/3\n",
    ")\n",
    "\n",
    "avg_score = behavior[\"score\"].mean()\n",
    "\n",
    "if avg_score < 0.4:\n",
    "    risk = \"High Risk - Reallocate immediately\"\n",
    "elif avg_score < 0.6:\n",
    "    risk = \"Moderate Risk - Document and monitor closely\"\n",
    "else:\n",
    "    risk = \"Low Risk - Reliable teammate\"\n",
    "\n",
    "print(\"Average Score:\", avg_score)\n",
    "print(\"Teammate Risk Level:\", risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75505dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f5fa9b-4ab5-4ed2-9bd4-139bc026579f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  global_share_pct  political_risk  ethical_risk  risk_score  \\\n",
      "0          DRC              70.0             0.9          0.85        0.88   \n",
      "1    Australia               4.0             0.2          0.10        0.16   \n",
      "2         Cuba               2.5             0.3          0.20        0.26   \n",
      "3  Philippines               2.0             0.4          0.25        0.34   \n",
      "\n",
      "   weighted_supply_risk  \n",
      "0                 61.60  \n",
      "1                  0.64  \n",
      "2                  0.65  \n",
      "3                  0.68  \n",
      "Total Cobalt Supply Chain Risk: 63.57000000000001\n"
     ]
    }
   ],
   "source": [
    "#Python Code: Simple ‚ÄúCobalt Supply Risk Model‚Äù\n",
    "import pandas as pd\n",
    "\n",
    "# Simple supply-risk model\n",
    "df = pd.DataFrame({\n",
    "    \"country\": [\"DRC\", \"Australia\", \"Cuba\", \"Philippines\"],\n",
    "    \"global_share_pct\": [70, 4, 2.5, 2],\n",
    "    \"political_risk\": [0.9, 0.2, 0.3, 0.4],  # 0=low, 1=high\n",
    "    \"ethical_risk\": [0.85, 0.1, 0.2, 0.25]\n",
    "})\n",
    "\n",
    "# Weighted Risk Score\n",
    "df[\"risk_score\"] = (\n",
    "    0.6 * df[\"political_risk\"] +\n",
    "    0.4 * df[\"ethical_risk\"]\n",
    ")\n",
    "\n",
    "df[\"weighted_supply_risk\"] = df[\"risk_score\"] * df[\"global_share_pct\"]\n",
    "\n",
    "total_risk = df[\"weighted_supply_risk\"].sum()\n",
    "\n",
    "print(df)\n",
    "print(\"Total Cobalt Supply Chain Risk:\", total_risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de74160b-a459-4ea6-9533-1c35d90f9e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "INCOME STATEMENT\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "                Line Item  Amount                                                                                         Calculation\n",
      "                  Revenue 12500.0                                                    Total sales from bouquets, events, subscriptions\n",
      "Cost of Goods Sold (COGS)  4800.0                   Flowers (3200) + Ribbons/Vases (900) + Packaging (300) + Delivery Materials (400)\n",
      "             Gross Profit  7700.0                                                                                      Revenue ‚Äì COGS\n",
      "       Operating Expenses  5300.0 Rent (2400) + Wages (1800) + Utilities (300) + Shopify/Website (150) + Marketing (400) + Misc (250)\n",
      "         Operating Income  2400.0                                                                   Gross Profit ‚Äì Operating Expenses\n",
      "         Interest Expense   120.0                                                                      Loan Balance (3500) √ó 0.034286\n",
      "Earnings Before Tax (EBT)  2280.0                                                                 Operating Income ‚Äì Interest Expense\n",
      "              Tax Expense   456.0                                                                                EBT √ó Tax Rate (20%)\n",
      "               Net Income  1824.0                                                                                   EBT ‚Äì Tax Expense\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "CASH FLOW STATEMENT\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "                 Category  Amount                                       Calculation\n",
      "           Beginning Cash  3200.0                            Cash at start of month\n",
      "Cash Flow From Operations  1920.0 Estimated: Operating Income √ó 80% cash conversion\n",
      " Cash Flow From Investing  -600.0   Purchase of equipment (e.g., new floral fridge)\n",
      " Cash Flow From Financing  1000.0                  New loan or capital contribution\n",
      "              Ending Cash  5520.0                  Beginning Cash + CFO + CFI + CFF\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "BALANCE SHEET\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Assets:\n",
      "\n",
      "Asset Category  Amount                             Calculation\n",
      "          Cash  5520.0 From Ending Cash in Cash Flow Statement\n",
      "     Inventory  3200.0      Unsold flowers & materials at cost\n",
      "     Equipment  7800.0             Cooler, shelves, POS, tools\n",
      "  Total Assets 16520.0            Cash + Inventory + Equipment\n",
      "\n",
      "Liabilties:\n",
      "\n",
      "Liability Category  Amount                          Calculation\n",
      "      Loan Payable    3500 Outstanding balance of business loan\n",
      "  Accounts Payable    1000             Unpaid supplier invoices\n",
      " Total Liabilities    4500      Loan Payable + Accounts Payable\n",
      "\n",
      "Equity:\n",
      "\n",
      "           Equity Category  Amount                      Calculation\n",
      "            Owner's Equity 12020.0 Total Assets ‚Äì Total Liabilities\n",
      "Total Liabilities + Equity 16520.0          Must equal Total Assets\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Summary Checks\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Net Income (should be ~1824): 1824.0\n",
      "Total Assets: 16520.0\n",
      "Total Liabilities: 4500\n",
      "Equity: 12020.0\n",
      "Assets == Liabilities + Equity ? True\n",
      "Ending Cash: 5520.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Lavender Roses Flower Shop Full Financial Statements with Calculation Breakdown \"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1. INPUT ASSUMPTIONS\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Revenue\n",
    "revenue = 12_500\n",
    "\n",
    "# COGS breakdown\n",
    "flowers = 3_200\n",
    "ribbons_vases = 900\n",
    "packaging = 300\n",
    "delivery_materials = 400\n",
    "cogs = flowers + ribbons_vases + packaging + delivery_materials\n",
    "\n",
    "# Operating expenses breakdown\n",
    "rent = 2_400\n",
    "wages = 1_800\n",
    "utilities = 300\n",
    "shopify_website = 150\n",
    "marketing = 400\n",
    "misc = 250\n",
    "operating_expenses = rent + wages + utilities + shopify_website + marketing + misc\n",
    "\n",
    "# Interest and tax\n",
    "loan_balance = 3_500\n",
    "monthly_interest_rate = 0.0342857  # chosen to approximate 120 interest\n",
    "interest_expense = round(loan_balance * monthly_interest_rate, 2)  # ‚âà 120\n",
    "tax_rate = 0.20\n",
    "\n",
    "# Cash flow assumptions\n",
    "beginning_cash = 3_200\n",
    "cash_from_investing = -600\n",
    "cash_from_financing = 1_000\n",
    "# We'll derive cash_from_operations from operating income later\n",
    "\n",
    "# Balance sheet assumptions (assets & liabilities)\n",
    "inventory = 3_200\n",
    "equipment = 7_800\n",
    "# We'll derive cash from cash flow and equity from A = L + E\n",
    "loan_payable = loan_balance\n",
    "accounts_payable = 1_000\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 2. INCOME STATEMENT\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "gross_profit = revenue - cogs\n",
    "operating_income = gross_profit - operating_expenses\n",
    "ebt = operating_income - interest_expense  # Earnings Before Tax\n",
    "tax_expense = round(ebt * tax_rate, 2)\n",
    "net_income = round(ebt - tax_expense, 2)\n",
    "\n",
    "income_statement = pd.DataFrame([\n",
    "    [\"Revenue\", revenue, \"Total sales from bouquets, events, subscriptions\"],\n",
    "    [\"Cost of Goods Sold (COGS)\", cogs,\n",
    "     f\"Flowers ({flowers}) + Ribbons/Vases ({ribbons_vases}) + \"\n",
    "     f\"Packaging ({packaging}) + Delivery Materials ({delivery_materials})\"],\n",
    "    [\"Gross Profit\", gross_profit, \"Revenue ‚Äì COGS\"],\n",
    "    [\"Operating Expenses\", operating_expenses,\n",
    "     f\"Rent ({rent}) + Wages ({wages}) + Utilities ({utilities}) + \"\n",
    "     f\"Shopify/Website ({shopify_website}) + Marketing ({marketing}) + Misc ({misc})\"],\n",
    "    [\"Operating Income\", operating_income, \"Gross Profit ‚Äì Operating Expenses\"],\n",
    "    [\"Interest Expense\", interest_expense, f\"Loan Balance ({loan_balance}) √ó {monthly_interest_rate:.6f}\"],\n",
    "    [\"Earnings Before Tax (EBT)\", ebt, \"Operating Income ‚Äì Interest Expense\"],\n",
    "    [\"Tax Expense\", tax_expense, f\"EBT √ó Tax Rate ({tax_rate:.0%})\"],\n",
    "    [\"Net Income\", net_income, \"EBT ‚Äì Tax Expense\"]\n",
    "], columns=[\"Line Item\", \"Amount\", \"Calculation\"])\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nINCOME STATEMENT\\n\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(income_statement.to_string(index=False))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 3. CASH FLOW STATEMENT\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Assume 80% of operating income converts to cash from operations\n",
    "cash_from_operations = round(operating_income * 0.80, 2)\n",
    "\n",
    "ending_cash = beginning_cash + cash_from_operations + cash_from_investing + cash_from_financing\n",
    "\n",
    "cash_flow_statement = pd.DataFrame([\n",
    "    [\"Beginning Cash\", beginning_cash, \"Cash at start of month\"],\n",
    "    [\"Cash Flow From Operations\", cash_from_operations,\n",
    "     \"Estimated: Operating Income √ó 80% cash conversion\"],\n",
    "    [\"Cash Flow From Investing\", cash_from_investing,\n",
    "     \"Purchase of equipment (e.g., new floral fridge)\"],\n",
    "    [\"Cash Flow From Financing\", cash_from_financing,\n",
    "     \"New loan or capital contribution\"],\n",
    "    [\"Ending Cash\", ending_cash,\n",
    "     \"Beginning Cash + CFO + CFI + CFF\"]\n",
    "], columns=[\"Category\", \"Amount\", \"Calculation\"])\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nCASH FLOW STATEMENT\\n\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(cash_flow_statement.to_string(index=False))\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 4. BALANCE SHEET\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "cash = ending_cash\n",
    "total_assets = cash + inventory + equipment\n",
    "\n",
    "total_liabilities = loan_payable + accounts_payable\n",
    "equity = total_assets - total_liabilities  # A = L + E ‚Üí E = A ‚Äì L\n",
    "\n",
    "assets_section = pd.DataFrame([\n",
    "    [\"Cash\", cash, \"From Ending Cash in Cash Flow Statement\"],\n",
    "    [\"Inventory\", inventory, \"Unsold flowers & materials at cost\"],\n",
    "    [\"Equipment\", equipment, \"Cooler, shelves, POS, tools\"],\n",
    "    [\"Total Assets\", total_assets, \"Cash + Inventory + Equipment\"]\n",
    "], columns=[\"Asset Category\", \"Amount\", \"Calculation\"])\n",
    "\n",
    "liabilities_section = pd.DataFrame([\n",
    "    [\"Loan Payable\", loan_payable, \"Outstanding balance of business loan\"],\n",
    "    [\"Accounts Payable\", accounts_payable, \"Unpaid supplier invoices\"],\n",
    "    [\"Total Liabilities\", total_liabilities, \"Loan Payable + Accounts Payable\"]\n",
    "], columns=[\"Liability Category\", \"Amount\", \"Calculation\"])\n",
    "\n",
    "equity_section = pd.DataFrame([\n",
    "    [\"Owner's Equity\", equity, \"Total Assets ‚Äì Total Liabilities\"],\n",
    "    [\"Total Liabilities + Equity\", total_liilities_plus_equity := total_liabilities + equity,\n",
    "     \"Must equal Total Assets\"]\n",
    "], columns=[\"Equity Category\", \"Amount\", \"Calculation\"])\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nBALANCE SHEET\\n\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Assets:\\n\")\n",
    "print(assets_section.to_string(index=False))\n",
    "print(\"\\nLiabilties:\\n\")\n",
    "print(liabilities_section.to_string(index=False))\n",
    "print(\"\\nEquity:\\n\")\n",
    "print(equity_section.to_string(index=False))\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# 5. Summary Check\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"\\nSummary Checks\")\n",
    "print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(f\"Net Income (should be ~1824): {net_income}\")\n",
    "print(f\"Total Assets: {total_assets}\")\n",
    "print(f\"Total Liabilities: {total_liabilities}\")\n",
    "print(f\"Equity: {equity}\")\n",
    "print(f\"Assets == Liabilities + Equity ? {total_assets == total_liabilities + equity}\")\n",
    "print(f\"Ending Cash: {ending_cash}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ae5168-cdaa-4658-8733-0b01013d8768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  material  stress_tolerance  structure_cohesion  clarity_factor  \\\n",
      "0     rock              0.20                0.10            0.05   \n",
      "1     rock              0.30                0.25            0.10   \n",
      "2  diamond              0.95                0.97            0.90   \n",
      "3  diamond              0.98                0.99            0.92   \n",
      "\n",
      "   pressure_index    classification  \n",
      "0           0.140     Rock Behavior  \n",
      "1           0.245     Rock Behavior  \n",
      "2           0.946  Diamond Behavior  \n",
      "3           0.971  Diamond Behavior  \n"
     ]
    }
   ],
   "source": [
    "#Python Code: ‚ÄúPressure Index‚Äù ‚Äî Modeling Diamond vs. Rock Behavior\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset of \"pressure response\" characteristics\n",
    "data = pd.DataFrame({\n",
    "    \"material\": [\"rock\", \"rock\", \"diamond\", \"diamond\"],\n",
    "    \"stress_tolerance\": [0.2, 0.3, 0.95, 0.98],  # how much pressure it can withstand\n",
    "    \"structure_cohesion\": [0.1, 0.25, 0.97, 0.99],  # internal integrity\n",
    "    \"clarity_factor\": [0.05, 0.10, 0.90, 0.92]  # figurative \"performance clarity\"\n",
    "})\n",
    "\n",
    "# Weighted score to determine \"value under pressure\"\n",
    "weights = {\n",
    "    \"stress_tolerance\": 0.5,\n",
    "    \"structure_cohesion\": 0.3,\n",
    "    \"clarity_factor\": 0.2\n",
    "}\n",
    "\n",
    "data[\"pressure_index\"] = (\n",
    "    data[\"stress_tolerance\"] * weights[\"stress_tolerance\"] +\n",
    "    data[\"structure_cohesion\"] * weights[\"structure_cohesion\"] +\n",
    "    data[\"clarity_factor\"] * weights[\"clarity_factor\"]\n",
    ")\n",
    "\n",
    "# Classification\n",
    "data[\"classification\"] = np.where(\n",
    "    data[\"pressure_index\"] >= 0.8,\n",
    "    \"Diamond Behavior\",\n",
    "    \"Rock Behavior\"\n",
    ")\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54a69546-22f3-4652-bbc9-f0e66b0d0694",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (23531093.py, line 426)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 426\u001b[0;36m\u001b[0m\n\u001b[0;31m    streamlit run dating_dashboard.py\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Python Code: ML Model to Detect ‚ÄúMixed Signals‚Äù\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example dataset (1 = consistent, 0 = mixed signals)\n",
    "data = pd.DataFrame({\n",
    "    \"text_frequency\": [10, 3, 15, 2, 8, 1, 12, 0],   # texts per day\n",
    "    \"response_time\": [2, 48, 1, 72, 5, 96, 3, 120], # hours to respond\n",
    "    \"follow_through\": [1, 0, 1, 0, 1, 0, 1, 0],     # does he keep plans?\n",
    "    \"initiates_contact\": [1, 0, 1, 0, 1, 0, 1, 0],  # initiates?\n",
    "    \"emotion_consistency\": [1, 0, 1, 0, 1, 0, 1, 0],# consistent tone?\n",
    "    \"label\": [1,0,1,0,1,0,1,0]                     # 1=consistent,0=mixed\n",
    "})\n",
    "\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Example evaluation of a new \"guy\"\n",
    "test = pd.DataFrame({\n",
    "    \"text_frequency\": [4],\n",
    "    \"response_time\": [36],\n",
    "    \"follow_through\": [0],\n",
    "    \"initiates_contact\": [0],\n",
    "    \"emotion_consistency\": [0]\n",
    "})\n",
    "\n",
    "prediction = model.predict(test)[0]\n",
    "result = \"Consistent King ‚ù§Ô∏è\" if prediction == 1 else \"Mixed Signal Menace üö©\"\n",
    "\n",
    "print(\"Prediction:\", result)\n",
    "\n",
    "\n",
    "#the code\n",
    "# ==========================================\n",
    "# MIXED SIGNALS vs GREEN-FLAG BF ML MODEL\n",
    "# PCA, \"RCA\", Classification, CV, Metrics\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(617)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. SYNTHETIC DATASET: BF BEHAVIOR FEATURES\n",
    "# ------------------------------------------\n",
    "# 0 = mixed signals (red flag)\n",
    "# 1 = green flag bf\n",
    "\n",
    "n_samples = 400\n",
    "\n",
    "# Features:\n",
    "# - text_frequency: avg messages per day\n",
    "# - response_time: avg hours to respond\n",
    "# - follow_through: ratio of plans kept\n",
    "# - initiates_contact: ratio of convos he starts\n",
    "# - emotional_consistency: 0‚Äì1 scale\n",
    "# - future_orientation: talks about future with you (0‚Äì1)\n",
    "# - boundary_respect: respects your time/space (0‚Äì1)\n",
    "# - accountability: owns mistakes (0‚Äì1)\n",
    "\n",
    "# Green-flag bfs\n",
    "n_green = n_samples // 2\n",
    "green = pd.DataFrame({\n",
    "    \"text_frequency\": np.random.normal(loc=10, scale=2, size=n_green).clip(3, 20),\n",
    "    \"response_time\": np.random.normal(loc=1.5, scale=0.7, size=n_green).clip(0.1, 4),\n",
    "    \"follow_through\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "    \"initiates_contact\": np.random.normal(loc=0.7, scale=0.1, size=n_green).clip(0.3, 1),\n",
    "    \"emotional_consistency\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "    \"future_orientation\": np.random.normal(loc=0.8, scale=0.1, size=n_green).clip(0.4, 1),\n",
    "    \"boundary_respect\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "    \"accountability\": np.random.normal(loc=0.85, scale=0.07, size=n_green).clip(0.5, 1),\n",
    "    \"label\": 1\n",
    "})\n",
    "\n",
    "# Mixed-signal guys\n",
    "n_mixed = n_samples - n_green\n",
    "mixed = pd.DataFrame({\n",
    "    \"text_frequency\": np.random.normal(loc=4, scale=2, size=n_mixed).clip(0, 15),\n",
    "    \"response_time\": np.random.normal(loc=24, scale=16, size=n_mixed).clip(1, 72),\n",
    "    \"follow_through\": np.random.normal(loc=0.4, scale=0.15, size=n_mixed).clip(0, 0.8),\n",
    "    \"initiates_contact\": np.random.normal(loc=0.3, scale=0.15, size=n_mixed).clip(0, 0.8),\n",
    "    \"emotional_consistency\": np.random.normal(loc=0.5, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "    \"future_orientation\": np.random.normal(loc=0.3, scale=0.2, size=n_mixed).clip(0, 0.9),\n",
    "    \"boundary_respect\": np.random.normal(loc=0.6, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "    \"accountability\": np.random.normal(loc=0.4, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "    \"label\": 0\n",
    "})\n",
    "\n",
    "df = pd.concat([green, mixed], ignore_index=True)\n",
    "\n",
    "print(\"Sample of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. TRAIN / TEST SPLIT\n",
    "# ------------------------------------------\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=617, stratify=y\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. STANDARDIZATION\n",
    "# ------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. PCA (Standard)\n",
    "# ------------------------------------------\n",
    "pca = PCA(n_components=2, random_state=617)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"\\nPCA explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. \"RCA\" ‚Äì Randomized PCA Variant\n",
    "#    (Here: PCA with randomized SVD solver)\n",
    "# ------------------------------------------\n",
    "rca = PCA(n_components=2, svd_solver=\"randomized\", random_state=617)\n",
    "X_train_rca = rca.fit_transform(X_train_scaled)\n",
    "X_test_rca = rca.transform(X_test_scaled)\n",
    "\n",
    "print(\"\\n'RCA' explained variance ratio:\", rca.explained_variance_ratio_)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 6. CLASSIFICATION MODEL\n",
    "#    Random Forest = flexible, good baseline\n",
    "# ------------------------------------------\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=617,\n",
    "    max_depth=6,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 7. CROSS-VALIDATION (Green Flag BF Detection)\n",
    "# ------------------------------------------\n",
    "cv_scores = cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# ------------------------------------------\n",
    "# 8. EVALUATION ON TEST SET\n",
    "# ------------------------------------------\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)   # precision for class 1 (green flag)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== TEST SET METRICS ===\")\n",
    "print(\"Accuracy :\", round(accuracy, 3))\n",
    "print(\"Precision:\", round(precision, 3))\n",
    "print(\"Recall   :\", round(recall, 3))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Mixed Signals (0)\", \"Green Flag (1)\"]))\n",
    "\n",
    "# ------------------------------------------\n",
    "# 9. CONFUSION MATRIX HEATMAP\n",
    "# ------------------------------------------\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Pred: Mixed\", \"Pred: Green\"],\n",
    "            yticklabels=[\"True: Mixed\", \"True: Green\"])\n",
    "plt.title(\"Confusion Matrix ‚Äì Mixed Signals vs Green Flag\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 10. PCA SCATTER PLOT (VISUALIZING BEHAVIOR SPACE)\n",
    "# ------------------------------------------\n",
    "plt.figure(figsize=(6, 5))\n",
    "scatter = plt.scatter(\n",
    "    X_train_pca[:, 0],\n",
    "    X_train_pca[:, 1],\n",
    "    c=y_train,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title(\"PCA of BF Behavior Space\")\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.legend(handles=scatter.legend_elements()[0],\n",
    "           labels=[\"Mixed Signals (0)\", \"Green Flag (1)\"],\n",
    "           title=\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 11. FEATURE IMPORTANCE BARPLOT\n",
    "# ------------------------------------------\n",
    "importances = clf.feature_importances_\n",
    "feature_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x=feature_importance.values, y=feature_importance.index)\n",
    "plt.title(\"Feature Importance ‚Äì What Predicts a Green-Flag BF?\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Behavior Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "############################################\n",
    "# ==========================================\n",
    "# MIXED SIGNALS vs GREEN-FLAG BF ML MODEL\n",
    "# + ROC & AUC\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(617)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1. SYNTHETIC DATASET\n",
    "# ------------------------------------------\n",
    "n_samples = 400\n",
    "\n",
    "n_green = n_samples // 2\n",
    "green = pd.DataFrame({\n",
    "    \"text_frequency\": np.random.normal(loc=10, scale=2, size=n_green).clip(3, 20),\n",
    "    \"response_time\": np.random.normal(loc=1.5, scale=0.7, size=n_green).clip(0.1, 4),\n",
    "    \"follow_through\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "    \"initiates_contact\": np.random.normal(loc=0.7, scale=0.1, size=n_green).clip(0.3, 1),\n",
    "    \"emotional_consistency\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "    \"future_orientation\": np.random.normal(loc=0.8, scale=0.1, size=n_green).clip(0.4, 1),\n",
    "    \"boundary_respect\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "    \"accountability\": np.random.normal(loc=0.85, scale=0.07, size=n_green).clip(0.5, 1),\n",
    "    \"label\": 1\n",
    "})\n",
    "\n",
    "n_mixed = n_samples - n_green\n",
    "mixed = pd.DataFrame({\n",
    "    \"text_frequency\": np.random.normal(loc=4, scale=2, size=n_mixed).clip(0, 15),\n",
    "    \"response_time\": np.random.normal(loc=24, scale=16, size=n_mixed).clip(1, 72),\n",
    "    \"follow_through\": np.random.normal(loc=0.4, scale=0.15, size=n_mixed).clip(0, 0.8),\n",
    "    \"initiates_contact\": np.random.normal(loc=0.3, scale=0.15, size=n_mixed).clip(0, 0.8),\n",
    "    \"emotional_consistency\": np.random.normal(loc=0.5, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "    \"future_orientation\": np.random.normal(loc=0.3, scale=0.2, size=n_mixed).clip(0, 0.9),\n",
    "    \"boundary_respect\": np.random.normal(loc=0.6, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "    \"accountability\": np.random.normal(loc=0.4, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "    \"label\": 0\n",
    "})\n",
    "\n",
    "df = pd.concat([green, mixed], ignore_index=True)\n",
    "\n",
    "print(\"Sample of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2. TRAIN / TEST SPLIT + SCALING\n",
    "# ------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=617, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3. PCA + \"RCA\"\n",
    "# ------------------------------------------\n",
    "pca = PCA(n_components=2, random_state=617)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(\"\\nPCA explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "rca = PCA(n_components=2, svd_solver=\"randomized\", random_state=617)\n",
    "X_train_rca = rca.fit_transform(X_train_scaled)\n",
    "X_test_rca = rca.transform(X_test_scaled)\n",
    "\n",
    "print(\"\\n'RCA' explained variance ratio:\", rca.explained_variance_ratio_)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4. CLASSIFIER\n",
    "# ------------------------------------------\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=617,\n",
    "    max_depth=6,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5. CROSS-VALIDATION\n",
    "# ------------------------------------------\n",
    "cv_scores = cross_val_score(clf, X_train_scaled, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(\"\\nCross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean CV Accuracy:\", cv_scores.mean())\n",
    "\n",
    "# ------------------------------------------\n",
    "# 6. METRICS ON TEST SET\n",
    "# ------------------------------------------\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]  # probability of green flag (1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== TEST SET METRICS ===\")\n",
    "print(\"Accuracy :\", round(accuracy, 3))\n",
    "print(\"Precision:\", round(precision, 3))\n",
    "print(\"Recall   :\", round(recall, 3))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred,\n",
    "                            target_names=[\"Mixed Signals (0)\", \"Green Flag (1)\"]))\n",
    "\n",
    "# ------------------------------------------\n",
    "# 7. CONFUSION MATRIX HEATMAP\n",
    "# ------------------------------------------\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=[\"Pred: Mixed\", \"Pred: Green\"],\n",
    "            yticklabels=[\"True: Mixed\", \"True: Green\"])\n",
    "plt.title(\"Confusion Matrix ‚Äì Mixed Signals vs Green Flag\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 8. ROC CURVE & AUC\n",
    "# ------------------------------------------\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve ‚Äì Green Flag BF Classifier\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 9. PCA SCATTER\n",
    "# ------------------------------------------\n",
    "plt.figure(figsize=(6, 5))\n",
    "scatter = plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1],\n",
    "                      c=y_train, alpha=0.7)\n",
    "plt.title(\"PCA of BF Behavior Space\")\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.legend(handles=scatter.legend_elements()[0],\n",
    "           labels=[\"Mixed Signals (0)\", \"Green Flag (1)\"],\n",
    "           title=\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 10. FEATURE IMPORTANCE\n",
    "# ------------------------------------------\n",
    "importances = clf.feature_importances_\n",
    "feature_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "sns.barplot(x=feature_importance.values, y=feature_importance.index)\n",
    "plt.title(\"Feature Importance ‚Äì What Predicts a Green-Flag BF?\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Behavior Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##########################################################\n",
    "streamlit run dating_dashboard.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Streamlit Dating Analytics Dashboard\n",
    "# Mixed Signals vs Green-Flag BF\n",
    "# ==========================================\n",
    "pip install streamlit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, accuracy_score,\n",
    "    precision_score, recall_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(617)\n",
    "\n",
    "# ---------- 1. Generate Synthetic Data (same logic as notebook) ----------\n",
    "\n",
    "def generate_data(n_samples=400):\n",
    "    n_green = n_samples // 2\n",
    "    green = pd.DataFrame({\n",
    "        \"text_frequency\": np.random.normal(loc=10, scale=2, size=n_green).clip(3, 20),\n",
    "        \"response_time\": np.random.normal(loc=1.5, scale=0.7, size=n_green).clip(0.1, 4),\n",
    "        \"follow_through\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "        \"initiates_contact\": np.random.normal(loc=0.7, scale=0.1, size=n_green).clip(0.3, 1),\n",
    "        \"emotional_consistency\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "        \"future_orientation\": np.random.normal(loc=0.8, scale=0.1, size=n_green).clip(0.4, 1),\n",
    "        \"boundary_respect\": np.random.normal(loc=0.9, scale=0.05, size=n_green).clip(0.7, 1),\n",
    "        \"accountability\": np.random.normal(loc=0.85, scale=0.07, size=n_green).clip(0.5, 1),\n",
    "        \"label\": 1\n",
    "    })\n",
    "\n",
    "    n_mixed = n_samples - n_green\n",
    "    mixed = pd.DataFrame({\n",
    "        \"text_frequency\": np.random.normal(loc=4, scale=2, size=n_mixed).clip(0, 15),\n",
    "        \"response_time\": np.random.normal(loc=24, scale=16, size=n_mixed).clip(1, 72),\n",
    "        \"follow_through\": np.random.normal(loc=0.4, scale=0.15, size=n_mixed).clip(0, 0.8),\n",
    "        \"initiates_contact\": np.random.normal(loc=0.3, scale=0.15, size=n_mixed).clip(0, 0.8),\n",
    "        \"emotional_consistency\": np.random.normal(loc=0.5, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "        \"future_orientation\": np.random.normal(loc=0.3, scale=0.2, size=n_mixed).clip(0, 0.9),\n",
    "        \"boundary_respect\": np.random.normal(loc=0.6, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "        \"accountability\": np.random.normal(loc=0.4, scale=0.2, size=n_mixed).clip(0, 1),\n",
    "        \"label\": 0\n",
    "    })\n",
    "\n",
    "    df = pd.concat([green, mixed], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "df = generate_data()\n",
    "\n",
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=617, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=617)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=617,\n",
    "    max_depth=6,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "y_proba = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# ---------- 2. Streamlit UI ----------\n",
    "\n",
    "st.set_page_config(page_title=\"Dating Analytics Dashboard\", layout=\"wide\")\n",
    "\n",
    "st.title(\"üíö Dating Analytics Dashboard: Mixed Signals vs Green-Flag BF\")\n",
    "st.write(\"Because your heart deserves **data-driven** decisions.\")\n",
    "\n",
    "st.sidebar.header(\"Describe His Behavior\")\n",
    "\n",
    "text_frequency = st.sidebar.slider(\n",
    "    \"Texts per day (average)\", min_value=0.0, max_value=20.0, value=6.0, step=0.5\n",
    ")\n",
    "response_time = st.sidebar.slider(\n",
    "    \"Average response time (hours)\", min_value=0.1, max_value=72.0, value=12.0, step=0.5\n",
    ")\n",
    "follow_through = st.sidebar.slider(\n",
    "    \"Follow-through on plans (0‚Äì1)\", min_value=0.0, max_value=1.0, value=0.6, step=0.05\n",
    ")\n",
    "initiates_contact = st.sidebar.slider(\n",
    "    \"Initiates contact ratio (0‚Äì1)\", min_value=0.0, max_value=1.0, value=0.5, step=0.05\n",
    ")\n",
    "emotional_consistency = st.sidebar.slider(\n",
    "    \"Emotional consistency (0‚Äì1)\", min_value=0.0, max_value=1.0, value=0.6, step=0.05\n",
    ")\n",
    "future_orientation = st.sidebar.slider(\n",
    "    \"Talks about future with you (0‚Äì1)\", min_value=0.0, max_value=1.0, value=0.4, step=0.05\n",
    ")\n",
    "boundary_respect = st.sidebar.slider(\n",
    "    \"Respects your boundaries (0‚Äì1)\", min_value=0.0, max_value=1.0, value=0.7, step=0.05\n",
    ")\n",
    "accountability = st.sidebar.slider(\n",
    "    \"Accountability (owns mistakes) (0‚Äì1)\", min_value=0.0, max_value=1.0, value=0.5, step=0.05\n",
    ")\n",
    "\n",
    "user_input = pd.DataFrame({\n",
    "    \"text_frequency\": [text_frequency],\n",
    "    \"response_time\": [response_time],\n",
    "    \"follow_through\": [follow_through],\n",
    "    \"initiates_contact\": [initiates_contact],\n",
    "    \"emotional_consistency\": [emotional_consistency],\n",
    "    \"future_orientation\": [future_orientation],\n",
    "    \"boundary_respect\": [boundary_respect],\n",
    "    \"accountability\": [accountability]\n",
    "})\n",
    "\n",
    "user_scaled = scaler.transform(user_input)\n",
    "user_proba = clf.predict_proba(user_scaled)[0, 1]\n",
    "user_pred = clf.predict(user_scaled)[0]\n",
    "\n",
    "st.subheader(\"üìä Prediction for This Guy\")\n",
    "\n",
    "if user_pred == 1:\n",
    "    st.success(f\"‚úÖ **Green-Flag BF Detected** ‚Äî Probability: {user_proba:.2%}\")\n",
    "else:\n",
    "    st.error(f\"üö© **Mixed Signal Menace** ‚Äî Probability of Green Flag: {user_proba:.2%}\")\n",
    "\n",
    "st.caption(\"Note: This is a playful model using synthetic data, not actual psychometrics.\")\n",
    "\n",
    "# ---------- 3. Metrics and Confusion Matrix ----------\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.subheader(\"Model Performance (Test Set)\")\n",
    "    st.metric(\"Accuracy\", f\"{accuracy:.3f}\")\n",
    "    st.metric(\"Precision (Green Flag)\", f\"{precision:.3f}\")\n",
    "    st.metric(\"Recall (Green Flag)\", f\"{recall:.3f}\")\n",
    "    st.metric(\"AUC\", f\"{auc_score:.3f}\")\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"Confusion Matrix\")\n",
    "    fig_cm, ax_cm = plt.subplots(figsize=(4, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", ax=ax_cm,\n",
    "                xticklabels=[\"Pred: Mixed\", \"Pred: Green\"],\n",
    "                yticklabels=[\"True: Mixed\", \"True: Green\"])\n",
    "    ax_cm.set_ylabel(\"True Label\")\n",
    "    ax_cm.set_xlabel(\"Predicted Label\")\n",
    "    st.pyplot(fig_cm)\n",
    "\n",
    "# ---------- 4. ROC Curve ----------\n",
    "\n",
    "st.subheader(\"ROC Curve ‚Äì Green Flag BF Classifier\")\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "fig_roc, ax_roc = plt.subplots(figsize=(4, 3))\n",
    "ax_roc.plot(fpr, tpr, label=f\"AUC = {auc_score:.3f}\")\n",
    "ax_roc.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "ax_roc.set_xlabel(\"False Positive Rate\")\n",
    "ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "ax_roc.legend()\n",
    "st.pyplot(fig_roc)\n",
    "\n",
    "# ---------- 5. PCA Plot ----------\n",
    "\n",
    "st.subheader(\"PCA Visualization of BF Behavior Space\")\n",
    "fig_pca, ax_pca = plt.subplots(figsize=(4, 3))\n",
    "scatter = ax_pca.scatter(X_train_pca[:, 0], X_train_pca[:, 1],\n",
    "                         c=y_train, alpha=0.7)\n",
    "ax_pca.set_xlabel(\"PC 1\")\n",
    "ax_pca.set_ylabel(\"PC 2\")\n",
    "legend_labels = [\"Mixed Signals (0)\", \"Green Flag (1)\"]\n",
    "ax_pca.legend(handles=scatter.legend_elements()[0],\n",
    "              labels=legend_labels,\n",
    "              title=\"Class\")\n",
    "st.pyplot(fig_pca)\n",
    "\n",
    "# ---------- 6. Feature Importance ----------\n",
    "\n",
    "st.subheader(\"Which Behaviors Matter Most?\")\n",
    "importances = clf.feature_importances_\n",
    "feature_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "fig_imp, ax_imp = plt.subplots(figsize=(5, 3))\n",
    "sns.barplot(x=feature_importance.values, y=feature_importance.index, ax=ax_imp)\n",
    "ax_imp.set_xlabel(\"Importance\")\n",
    "ax_imp.set_ylabel(\"Behavior Feature\")\n",
    "st.pyplot(fig_imp)\n",
    "\n",
    "st.caption(\"Use this to decide where your standards stay non-negotiable üíÖ.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
